// AiChat/services/llm.js

// ğŸ”¥ğŸ”¥ğŸ”¥ [æ–°å¢] è¡¥å…¨ç¼ºå¤±çš„é…ç½®è·å–å‡½æ•°ï¼Œä¾› create.vue è°ƒç”¨ ğŸ”¥ğŸ”¥ğŸ”¥
export const getCurrentLlmConfig = () => {
    try {
        const schemes = uni.getStorageSync('app_llm_schemes') || [];
        const index = uni.getStorageSync('app_current_scheme_index') || 0;
        
        if (schemes.length > 0 && index >= 0 && index < schemes.length) {
            return schemes[index];
        }
    } catch (e) {
        console.error('è·å–é…ç½®å¤±è´¥:', e);
    }
    return null;
};

// ğŸ‘‡ğŸ‘‡ğŸ‘‡ ä¸‹é¢æ˜¯ä½ åŸæœ‰çš„ä»£ç ï¼Œå®Œå…¨ä¿æŒä¸åŠ¨ ğŸ‘‡ğŸ‘‡ğŸ‘‡
export const LLM = {
  /**
   * ç»Ÿä¸€çš„ LLM èŠå¤©æ¥å£
   * @param {Object} params
   * @param {Object} params.config - { provider, apiKey, baseUrl, model }
   * @param {Array} params.messages - èŠå¤©è®°å½• [{role: 'user', content: '...'}, ...]
   * @param {String} [params.systemPrompt] - (å¯é€‰) ç³»ç»ŸæŒ‡ä»¤
   * @param {Boolean} [params.jsonMode] - (å¯é€‰) æ˜¯å¦å¼ºåˆ¶ JSON æ¨¡å¼
   * @returns {Promise<String>} - è¿”å› AI çš„å›å¤æ–‡æœ¬
   */
  async chat({ config, messages, systemPrompt, temperature = 0.7, maxTokens = 1500, jsonMode = false }) {
    if (!config || !config.apiKey) throw new Error('API é…ç½®ç¼ºå¤±');

    let baseUrl = config.baseUrl || '';
    if (baseUrl.endsWith('/')) baseUrl = baseUrl.slice(0, -1);
    
    let targetUrl = '';
    let header = { 'Content-Type': 'application/json' };
    let requestBody = {};
    
    // ---------------------------------------------------------
    // A. é€‚é… Gemini æ ¼å¼
    // ---------------------------------------------------------
    if (config.provider === 'gemini') {
        const cleanBase = 'https://generativelanguage.googleapis.com';
        targetUrl = `${cleanBase}/v1beta/models/${config.model}:generateContent?key=${config.apiKey}`;
        
        // Gemini çš„ role åªæœ‰ 'user' å’Œ 'model'
        const geminiContents = messages.map(m => ({
            role: m.role === 'assistant' || m.role === 'model' ? 'model' : 'user',
            parts: [{ text: m.content }]
        }));
        
        requestBody = {
            contents: geminiContents,
            generationConfig: {
                temperature: temperature,
                maxOutputTokens: maxTokens,
                // ğŸŒŸ Gemini çš„ JSON æ¨¡å¼å¼€å…³
                responseMimeType: jsonMode ? "application/json" : "text/plain"
            }
        };
        
        if (systemPrompt) {
            // ğŸ› ï¸ ä¿®æ­£ï¼šGemini çš„ system_instruction.parts å¿…é¡»æ˜¯æ•°ç»„
            requestBody.system_instruction = { 
                parts: [{ text: systemPrompt }] 
            };
        }
    } 
    // ---------------------------------------------------------
    // B. é€‚é… OpenAI / å…¼å®¹æ ¼å¼ (DeepSeek, GPT-4, etc.)
    // ---------------------------------------------------------
    else {
        targetUrl = `${baseUrl}/chat/completions`;
        header['Authorization'] = `Bearer ${config.apiKey}`;
        
        const openAIMessages = [...messages];
        // OpenAI å°† System Prompt æ”¾åœ¨ messages æ•°ç»„çš„ç¬¬ä¸€æ¡
        if (systemPrompt) {
            openAIMessages.unshift({ role: "system", content: systemPrompt });
        }
        
        requestBody = {
            model: config.model,
            messages: openAIMessages,
            max_tokens: maxTokens,
            temperature: temperature,
            stream: false
        };
        
        if (jsonMode) {
             // ğŸŒŸ OpenAI çš„ JSON æ¨¡å¼å¼€å…³
             // æ³¨æ„ï¼šå¼€å¯æ­¤æ¨¡å¼æ—¶ï¼ŒPrompt ä¸­å¿…é¡»åŒ…å« "JSON" å­—æ ·
             requestBody.response_format = { type: "json_object" };
        }
    }

    // ---------------------------------------------------------
    // C. å‘èµ·è¯·æ±‚ & ç»Ÿä¸€è§£æ
    // ---------------------------------------------------------
    try {
            const res = await uni.request({
                url: targetUrl, 
                method: 'POST', 
                header, 
                data: requestBody, 
                sslVerify: false
            });
    
            if (res.statusCode !== 200) {
                const errorMsg = res.data?.error?.message || `API è¯·æ±‚å¤±è´¥: ${res.statusCode}`;
                console.error('[LLM Error Detail]', res.data);
                throw new Error(errorMsg);
            }
    
            let content = '';
            
            // è§£æ Gemini å“åº”
            if (config.provider === 'gemini') {
                content = res.data?.candidates?.[0]?.content?.parts?.[0]?.text;
            } 
            // ğŸ‘‡ğŸ‘‡ğŸ‘‡ ä¿®æ”¹è¿™é‡Œï¼šè§£æ OpenAI / DeepSeek å“åº” ğŸ‘‡ğŸ‘‡ğŸ‘‡
            else {
                let data = res.data;
                // å…¼å®¹æŸäº›å¹³å°è¿”å› string çš„æƒ…å†µ
                if (typeof data === 'string') { 
                    try { data = JSON.parse(data); } catch(e){} 
                }
                
                // è·å– message å¯¹è±¡
                const choice = data?.choices?.[0];
                const message = choice?.message;
                
                content = message?.content || '';
    
                // ğŸ”¥ğŸ”¥ğŸ”¥ [æ–°å¢] é€‚é… DeepSeek R1 çš„æ€ç»´é“¾å­—æ®µ ğŸ”¥ğŸ”¥ğŸ”¥
                // DeepSeek ä¼šæŠŠæ€è€ƒè¿‡ç¨‹æ”¾åœ¨ reasoning_content é‡Œ
                // æˆ‘ä»¬æ‰‹åŠ¨æŠŠå®ƒåŒ…åœ¨ <think> æ ‡ç­¾é‡Œæ‹¼æ¥åˆ°å¼€å¤´ï¼Œè¿™æ ·å‰ç«¯å°±èƒ½è¯†åˆ«äº†
                if (message?.reasoning_content) {
                    // é˜²æ­¢é‡å¤æ‹¼æ¥
                    if (!content.includes('<think>')) {
                        content = `<think>${message.reasoning_content}</think>\n${content}`;
                    }
                }
            }
        
        return content || '';
    } catch (e) {
        console.error('[LLM Service Exception]', e);
        throw e;
    }
  }
};